LLerem Knowledge Assistant

LLerem Knowledge Assistant is a Retrieval-Augmented Generation (RAG) chatbot built to answer questions using a private knowledge base. It combines semantic search with conversational memory to deliver accurate, context-aware responses while keeping hallucinations in check.

The chatbot indexes Markdown documents into a vector database and retrieves only the most relevant content for each query. It supports conversation-aware retrieval, meaning previous user questions influence document search, while each response is grounded in freshly selected context.

âœ¨ Key Features

ğŸ” Semantic search with similarity scoring using Chroma

ğŸ§© Conversation-aware retrieval across multiple turns

ğŸ“„ Dynamic context construction from relevant documents only

ğŸ¤– LLM-powered responses via OpenAI models

ğŸ§  Clear separation of chat memory and document evidence

ğŸ–¥ï¸ Interactive Gradio UI with retrieved document preview

ğŸ“¦ Local vector store persistence

ğŸ› ï¸ Tech Stack

LangChain

ChromaDB

HuggingFace Embeddings (MiniLM)

OpenAI GPT models

Gradio

Python

ğŸ¯ Use Cases

Internal company knowledge assistants

Documentation Q&A bots

Private RAG-based chat systems

Learning and experimentation with modern RAG architectures

This project demonstrates a production-style RAG pipeline, emphasizing relevance filtering, controlled context injection, and conversational coherence.
